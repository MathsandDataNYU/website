<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Math and Data</title>
    <link>https://mathsanddatanyu.github.io/website/categories/golang/index.xml</link>
    <description>Recent content on Math and Data</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="https://mathsanddatanyu.github.io/website/categories/golang/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>reading</title>
      <link>https://mathsanddatanyu.github.io/website/news/reading/</link>
      <pubDate>Tue, 24 Jan 2017 15:40:00 -0500</pubDate>
      
      <guid>https://mathsanddatanyu.github.io/website/news/reading/</guid>
      <description>&lt;p&gt;This week we are starting two weekly reading groups.
One will study &lt;a href=&#34;https://github.com/MathsandDataNYU/HighDimProba_spring17&#34;&gt;topics on high-dimensional Probability&lt;/a&gt;,
whereas the other will focus on selected &lt;a href=&#34;https://github.com/MathsandDataNYU/StatPhysics_spring17&#34;&gt;topics on Statistical Physics&lt;/a&gt;. You can check present and past reading groups in the corresponding &lt;a href=&#34;reading&#34;&gt;page&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reading Groups</title>
      <link>https://mathsanddatanyu.github.io/website/reading/</link>
      <pubDate>Tue, 24 Jan 2017 15:36:26 -0500</pubDate>
      
      <guid>https://mathsanddatanyu.github.io/website/reading/</guid>
      <description>

&lt;p&gt;The Mad group hosts semester-long thematic reading groups.
Publicly accessible here.&lt;/p&gt;

&lt;h4 id=&#34;high-dimensional-probability-https-github-com-mathsanddatanyu-highdimproba-spring17&#34;&gt;&lt;a href=&#34;https://github.com/MathsandDataNYU/HighDimProba_spring17&#34;&gt;High Dimensional Probability&lt;/a&gt;&lt;/h4&gt;

&lt;h4 id=&#34;statistical-physics-https-github-com-mathsanddatanyu-statphysics-spring17&#34;&gt;&lt;a href=&#34;https://github.com/MathsandDataNYU/StatPhysics_spring17&#34;&gt;Statistical Physics&lt;/a&gt;&lt;/h4&gt;
</description>
    </item>
    
    <item>
      <title>Phd Program in the Mad group </title>
      <link>https://mathsanddatanyu.github.io/website/news/mediumarticle/</link>
      <pubDate>Fri, 23 Dec 2016 11:01:01 -0500</pubDate>
      
      <guid>https://mathsanddatanyu.github.io/website/news/mediumarticle/</guid>
      <description>&lt;p&gt;Check out these articles if you are interested in applying to our PhD program!&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://medium.com/@NYUDataScience/ph-d-in-data-science-the-math-data-group-f055b52c3826#.1e0bbwrvb&#34;&gt;PhD in Data Science : The MaD Group&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://medium.com/@NYUDataScience/phd-in-data-science-application-tips-875750c6ac87#.ee228cxwu&#34;&gt;PhD Application tips!&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Welcome to the Mad site!</title>
      <link>https://mathsanddatanyu.github.io/website/news/first/</link>
      <pubDate>Thu, 22 Dec 2016 14:51:18 -0500</pubDate>
      
      <guid>https://mathsanddatanyu.github.io/website/news/first/</guid>
      <description>&lt;p&gt;The Mad (Math and Data) group was created in fall 2016 by
Afonso Bandeira, Joan Bruna and Carlos Fernandez-Granda, three Assistant
Professors at Courant Institute and the Center for Data Science.&lt;/p&gt;

&lt;p&gt;We are always in the lookout for highly motivated students interested
in understanding and developing the fundamental mathematical structures underpinning
modern data analysis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Students and Visitors</title>
      <link>https://mathsanddatanyu.github.io/website/studentsvisitors/</link>
      <pubDate>Thu, 22 Dec 2016 14:48:53 -0500</pubDate>
      
      <guid>https://mathsanddatanyu.github.io/website/studentsvisitors/</guid>
      <description>

&lt;h4 id=&#34;augustin-cosse-http-www-augustincosse-com-oct-2016&#34;&gt;&lt;a href=&#34;http://www.augustincosse.com&#34;&gt;Augustin Cosse&lt;/a&gt; (oct 2016 - )&lt;/h4&gt;

&lt;p&gt;Postdoc; Tensor methods, inverse problems.&lt;/p&gt;

&lt;h4 id=&#34;alex-nowak-sep-2016-may-2017&#34;&gt;Alex Nowak (sep 2016 - may 2017 )&lt;/h4&gt;

&lt;p&gt;Visiting Student; deep learning, harmonic analysis&lt;/p&gt;

&lt;h4 id=&#34;thomas-moreau-jan-2017-mar-2017&#34;&gt;Thomas Moreau (jan 2017 - mar 2017)&lt;/h4&gt;

&lt;p&gt;Visiting Student; high-dimensional statistics, machine learning&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Faculty</title>
      <link>https://mathsanddatanyu.github.io/website/faculty/</link>
      <pubDate>Thu, 22 Dec 2016 14:48:45 -0500</pubDate>
      
      <guid>https://mathsanddatanyu.github.io/website/faculty/</guid>
      <description>

&lt;hr /&gt;

&lt;h2 id=&#34;core&#34;&gt;Core&lt;/h2&gt;

&lt;h4 id=&#34;afonso-s-bandeira-http-www-cims-nyu-edu-bandeira&#34;&gt;&lt;a href=&#34;http://www.cims.nyu.edu/~bandeira/&#34;&gt;Afonso S. Bandeira&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Assistant Professor, Department of Mathematics and Center for Data Science.&lt;/p&gt;

&lt;h4 id=&#34;joan-bruna-http-www-cims-nyu-edu-bruna&#34;&gt;&lt;a href=&#34;http://www.cims.nyu.edu/~bruna/&#34;&gt;Joan Bruna&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Assistant Professor, Department of Computer Science, Center for Data Science and Mathematics (affiliated).&lt;/p&gt;

&lt;h4 id=&#34;carlos-fernandez-granda-http-www-cims-nyu-edu-cfgranda&#34;&gt;&lt;a href=&#34;http://www.cims.nyu.edu/~cfgranda/&#34;&gt;Carlos Fernandez-Granda&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Assistant Professor, Department of Mathematics and Center for Data Science.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;affiliated&#34;&gt;Affiliated&lt;/h2&gt;

&lt;h5 id=&#34;xi-chen-http-people-stern-nyu-edu-xchen3&#34;&gt;&lt;a href=&#34;http://people.stern.nyu.edu/xchen3/&#34;&gt;Xi Chen&lt;/a&gt;&lt;/h5&gt;

&lt;p&gt;Assistant Professor, IOMS, Stern School.&lt;/p&gt;

&lt;h5 id=&#34;sinan-gunturk-https-www-cims-nyu-edu-gunturk&#34;&gt;&lt;a href=&#34;https://www.cims.nyu.edu/~gunturk/&#34;&gt;Sinan Gunturk&lt;/a&gt;&lt;/h5&gt;

&lt;p&gt;Professor, Department of Mathematics, Courant Institute.&lt;/p&gt;

&lt;h5 id=&#34;andy-majda-http-www-math-nyu-edu-faculty-majda&#34;&gt;&lt;a href=&#34;http://www.math.nyu.edu/faculty/majda/&#34;&gt;Andy Majda&lt;/a&gt;&lt;/h5&gt;

&lt;p&gt;Professor, Department of Mathematics and Climate, Atmosphere and Ocean Science, Courant Institute.&lt;/p&gt;

&lt;h5 id=&#34;adi-rangan-http-www-cims-nyu-edu-rangan&#34;&gt;&lt;a href=&#34;http://www.cims.nyu.edu/~rangan/&#34;&gt;Adi Rangan&lt;/a&gt;&lt;/h5&gt;

&lt;p&gt;Associate Professor, Department of Mathematics, Courant Institute.&lt;/p&gt;

&lt;h5 id=&#34;eero-simoncelli-http-www-cns-nyu-edu-eero&#34;&gt;&lt;a href=&#34;http://www.cns.nyu.edu/~eero/&#34;&gt;Eero Simoncelli&lt;/a&gt;&lt;/h5&gt;

&lt;p&gt;Silver Professor, Neural Science, Mathematics and Psychology;&lt;br /&gt;
Investigator, Howard Hughes Medical Institute.&lt;/p&gt;

&lt;h5 id=&#34;esteban-tabak-http-www-math-nyu-edu-faculty-tabak&#34;&gt;&lt;a href=&#34;http://www.math.nyu.edu/faculty/tabak/&#34;&gt;Esteban Tabak&lt;/a&gt;&lt;/h5&gt;

&lt;p&gt;Professor, Department of Mathematics, Courant Institute.&lt;/p&gt;

&lt;h5 id=&#34;eric-vanden-eijnden-http-www-cims-nyu-edu-eve2&#34;&gt;&lt;a href=&#34;http://www.cims.nyu.edu/~eve2/&#34;&gt;Eric Vanden-Eijnden&lt;/a&gt;&lt;/h5&gt;

&lt;p&gt;Professor, Department of Mathematics, Courant Institute.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>the MaD Seminar</title>
      <link>https://mathsanddatanyu.github.io/website/seminar/</link>
      <pubDate>Thu, 22 Dec 2016 14:45:56 -0500</pubDate>
      
      <guid>https://mathsanddatanyu.github.io/website/seminar/</guid>
      <description>

&lt;p&gt;The MaD seminar features leading specialists at the interface
of Applied Mathematics, Statistics and Machine Learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Room:&lt;/strong&gt; Auditorium Hall 150, Center for Data Science, NYU, &lt;a href=&#34;https://www.google.com/maps/place/NYU+Center+for+Data+Science/@40.735016,-73.9969907,17z/data=!3m1!4b1!4m5!3m4!1s0x89c2599787834ad9:0x5dd8af15d9fbc8a3!8m2!3d40.735016!4d-73.994802&#34;&gt;60 5th ave&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Time:&lt;/strong&gt; 2:30pm-3:30pm, Reception will follow.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Subscribe to the Seminar Mailing list &lt;a href=&#34;http://cims.nyu.edu/mailman/listinfo/mad&#34;&gt;here&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;schedule-with-confirmed-speakers&#34;&gt;Schedule with Confirmed Speakers&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Speaker&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Title&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Jan 26&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://statweb.stanford.edu/~donoho/&#34;&gt;Dave Donoho&lt;/a&gt; (Stanford)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;#donoho&#34;&gt;Optimal Shrinkage of Covariance Matrices in light of the spiked covariance model&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Feb 2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.stat.columbia.edu/~gelman/&#34;&gt;Andrew Gelman&lt;/a&gt; (Columbia)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;#gelman&#34;&gt;Taking Bayesian Inference Seriously&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;del&gt;Feb 9&lt;/del&gt; Mar 20&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.math.nyu.edu/faculty/greengar/&#34;&gt;Leslie Greengard&lt;/a&gt; (Courant)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;#greengard&#34;&gt;Inverse problems in acoustic scattering and cryo-electron microscopy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Feb 16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://cpsc.yale.edu/people/ronald-coifman&#34;&gt;Ronald Coifman&lt;/a&gt; (Yale)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;#coifman&#34;&gt;Organization and Analysis on data tensors&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Feb 23&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.columbia.edu/~jw2966/&#34;&gt;John Wright&lt;/a&gt; (Columbia)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;#wright&#34;&gt;Nonconvex Recovery of Low-Complexity Models&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Mar 2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.tu-berlin.de/?108957&#34;&gt;Gitta Kutyniok&lt;/a&gt; (TU Berlin)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TBA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Mar 9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www-math.mit.edu/~rigollet/&#34;&gt;Philippe Rigollet&lt;/a&gt; (MIT)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TBA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Mar 16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;strong&gt;SPRING BREAK&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Mar 23&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://web.math.princeton.edu/~amits/&#34;&gt;Amit Singer&lt;/a&gt; (Princeton)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TBA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Mar 30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.di.ens.fr/~mallat/&#34;&gt;Stephane Mallat&lt;/a&gt; (ENS Ulm)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TBA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Apr 6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~brecht/&#34;&gt;Ben Recht&lt;/a&gt; (UC Berkeley)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TBA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Apr 13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.rci.rutgers.edu/~wub1/&#34;&gt;Waheed Bajwa&lt;/a&gt; (Rutgers)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TBA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Apr 20&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://web.stanford.edu/~montanar/&#34;&gt;Andrea Montanari&lt;/a&gt; (Stanford)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TBA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Apr 27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://users.cms.caltech.edu/~jtropp/&#34;&gt;Joel Tropp&lt;/a&gt;  (Caltech)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TBA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;May 4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.math.ucdavis.edu/~strohmer/?p=home&#34;&gt;Thomas Strohmer&lt;/a&gt; (UC Davis)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TBA&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;abstracts&#34;&gt;Abstracts&lt;/h3&gt;

&lt;h4 id=&#34;a-name-donoho-a-dave-donoho-optimal-shrinkage-of-covariance-matrices-in-light-of-the-spiked-covariance-model&#34;&gt;&lt;a name=&#34;donoho&#34;&gt;&lt;/a&gt; Dave Donoho: Optimal Shrinkage of Covariance Matrices in light of the Spiked Covariance Model&lt;/h4&gt;

&lt;p&gt;(joint work with Behrooz Ghorbani, Stanford)&lt;/p&gt;

&lt;p&gt;In recent years, there has been a great deal of excitement about &amp;lsquo;big data&amp;rsquo; and about the new research problems posed by a world of vastly enlarged datasets. In response, the field of Mathematical Statistics increasingly studies problems where the number of variables measured is comparable to or even larger than the number of observations. Numerous fascinating mathematical phenomena arise in this regime; and in particular theorists discovered that the traditional approach to covariance estimation needs to be completely rethought, by appropriately shrinking the eigenvalues of the empirical covariance matrix.&lt;/p&gt;

&lt;p&gt;This talk briefly reviews  advances by researchers in random matrix theory who in recent years solved completely the properties of eigenvalues and eigenvectors under the so-called spiked covariance model.   By applying these results it is now possible to obtain the exact optimal nonlinear shrinkage of eigenvalues for certain specific measures of performance, as has been shown in the case of Frobenius loss by Nobel and Shabalin, and for many other performance measures by Donoho, Gavish, and Johnstone.&lt;/p&gt;

&lt;p&gt;In this talk, we focus on recent results of the author and Behrooz Ghorbani on optimal shrinkage for  the condition number of the relative error matrix; this presents new subtleties. The exact optimal solutions will be described, and stylized applications to Muti-User Covariance estimation and Multi-Task Discriminant Analysis will be developed.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;a-name-gelman-a-andrew-gelman-taking-bayesian-inference-seriously&#34;&gt;&lt;a name=&#34;gelman&#34;&gt;&lt;/a&gt; Andrew Gelman: Taking Bayesian Inference Seriously&lt;/h4&gt;

&lt;p&gt;Over the years I have been moving toward the use of informative priors in more and more of my applications. I will discuss several examples from theory, application, and computing where traditional noninformative priors lead to disaster, but a little bit of prior information can make everything work out. Informative priors also can resolve some of the questions of replication and multiple comparisons that have recently shook the world of science. It’s funny for me to say this, after having practiced Bayesian statistics for nearly thirty years, but I’m only now realizing the true value of the prior distribution.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;a-name-greengard-a-leslie-greengard-inverse-problems-in-acoustic-scattering-and-cryo-electron-microscopy&#34;&gt;&lt;a name=&#34;greengard&#34;&gt;&lt;/a&gt; Leslie Greengard: Inverse problems in acoustic scattering and cryo-electron microscopy&lt;/h4&gt;

&lt;p&gt;A variety of problems in image reconstruction give rise to large-scale, nonlinear and non-convex optimization problems. We will show how recursive linearization combined with suitable fast solvers are bringing such problems within practical reach, with an emphasis on acoustic scattering and protein structure determination via cryo-electron microscopy.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;a-name-coifman-a-ronald-coifman-organization-and-analysis-on-data-tensors&#34;&gt;&lt;a name=&#34;coifman&#34;&gt;&lt;/a&gt; Ronald Coifman: Organization and Analysis on data tensors&lt;/h4&gt;

&lt;p&gt;Our goal is to illustrate and give an overview of various emerging methodologies to geometrize tensor data and build analytics on that foundation.&lt;/p&gt;

&lt;p&gt;Starting with conventional data bases given as matrices , where we organize simultaneously rows and columns , viewed as functions of each other . We extend the  process  to higher order tensors,on which we build joint geometries.&lt;/p&gt;

&lt;p&gt;We will describe various applications to the study of questionnaires , medical and genetic data , neuronal dynamics in various regimes. In particular we will discuss a useful integration of these analytic tools with deep nets and the features they reveal.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;a-name-wright-a-john-wright-nonconvex-recovery-of-low-complexity-models&#34;&gt;&lt;a name=&#34;wright&#34;&gt;&lt;/a&gt; John Wright: Nonconvex Recovery of Low-Complexity Models&lt;/h4&gt;

&lt;p&gt;Nonconvex optimization plays important role in wide range of areas of science and engineering — from learning feature representations for visual classification, to reconstructing images in biology, medicine and astronomy, to disentangling spikes from multiple neurons. The worst case theory for nonconvex optimization is dismal: in general, even guaranteeing a local minimum is NP hard. However, in these and other applications, very simple iterative methods such as gradient descent often perform surprisingly well.&lt;/p&gt;

&lt;p&gt;In this talk, I will discuss examples of nonconvex optimization problems that can be solved to global optimality using simple iterative methods, which succeed independent of initialization. These include variants of the sparse dictionary learning problem, image recovery from certain types of phaseless measurements, and variants of the sparse blind deconvolution problem. These problems possess a characteristic structure, in which (i) all local minima are global, and (ii) the energy landscape does not have any “flat” saddle points. For each of the aforementioned problems, this geometric structure allows us to obtain new types of performance guarantees. I will motivate these problems from applications in imaging and computer vision, and describe how this viewpoint leads to new approaches to analyzing electron microscopy data.&lt;/p&gt;

&lt;p&gt;Joint work with Ju Sun (Stanford), Qing Qu (Columbia), Yuqian Zhang (Columbia), Yenson Lau (Columbia) Sky Cheung, (Columbia), Abhay Pasupathy (Columbia)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>